{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import TensorDataset,DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data/ml-1m/ratings.dat',sep='::', names=['user','item','rating','timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978300760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "      <td>978302109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "      <td>978301968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "      <td>978300275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "      <td>978824291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user  item  rating  timestamp\n",
       "0     1  1193       5  978300760\n",
       "1     1   661       3  978302109\n",
       "2     1   914       3  978301968\n",
       "3     1  3408       4  978300275\n",
       "4     1  2355       5  978824291"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "user2id = {}\n",
    "item2id = {}\n",
    "for idx, user in enumerate(data['user'].unique().tolist()):\n",
    "    user2id[user] = idx\n",
    "for idx, item in enumerate(data['item'].unique().tolist()):\n",
    "    item2id[item] = idx\n",
    "    \n",
    "data['user'] = data['user'].map(user2id)\n",
    "data['item'] = data['item'].map(item2id)\n",
    "data = data.sort_values(by=['user', 'timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成训练测试数据，对于每个用户的数据最后一个item为测试，其他item为训练\n",
    "def neg_sample_item(num_item, neg_num,item_list):\n",
    "    neg_list = []\n",
    "    while len(neg_list)<neg_num:\n",
    "        neg_item = np.random.choice(num_item, 1)[0]\n",
    "        while neg_item in item_list:\n",
    "            neg_item = np.random.choice(num_item, 1)[0]\n",
    "        neg_list.append(neg_item)\n",
    "    return neg_list\n",
    "\n",
    "def generate_train_test_data(data, neg_num):\n",
    "    # user rating item\n",
    "    num_item = len(data['item'].unique())\n",
    "    \n",
    "    train = []\n",
    "    test = []\n",
    "    # split data\n",
    "    for uid in data['user'].unique():\n",
    "        item_list = data[data['user']==uid]['item'].tolist()\n",
    "        for i in range(len(item_list)-8):\n",
    "            item_seq = item_list[i:i+8]\n",
    "            if i == len(item_list)-9:\n",
    "                neg_list = neg_sample_item(num_item, neg_num,item_list)\n",
    "                result_slice = [uid] + item_seq + neg_list\n",
    "                test.append(result_slice)\n",
    "            else:\n",
    "                neg_list = neg_sample_item(num_item, neg_num,item_list)\n",
    "                result_slice = [uid] + item_seq + neg_list\n",
    "                train.append(result_slice)\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 50s, sys: 1.82 s, total: 3min 52s\n",
      "Wall time: 3min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_data, test_data = generate_train_test_data(data, 3)\n",
    "\n",
    "train_data = torch.from_numpy(np.array(train_data))\n",
    "test_data = torch.from_numpy(np.array(test_data))\n",
    "train_x = train_data[:,:6]\n",
    "train_y = train_data[:,6:]\n",
    "\n",
    "# construct dataset for train test\n",
    "train_dataset = TensorDataset(train_x, train_y)\n",
    "dataloader = DataLoader(dataset=train_dataset, batch_size=512, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttenion(nn.Module):\n",
    "    def __init__(self, embedding_dim):\n",
    "        \"\"\"\n",
    "        embeding_dim: int, laten vector dim of item\n",
    "        \"\"\"\n",
    "        super(SelfAttenion, self).__init__()\n",
    "        self.linear1 = nn.Linear(embedding_dim, embedding_dim)\n",
    "        self.linear1.weight.data.normal_(mean=0, std=np.sqrt(2.0 / embedding_dim))\n",
    "        # self.linear2 = nn.Linear(embedding_dim, embedding_dim)\n",
    "        # init weight\n",
    "        # nn.init.normal_(self.linear1.weight, mean=0, std=np.sqrt(2.0 / embedding_dim)\n",
    "    \n",
    "    def forward(self, item_embedding):\n",
    "        \"\"\"\n",
    "        item_embeding: L*d user history L squence interaction item\n",
    "        \"\"\"\n",
    "        Q = F.relu(self.linear1(item_embedding))\n",
    "        K = F.relu(self.linear1(item_embedding))\n",
    "        d = torch.FloatTensor([100]).cuda()\n",
    "        affinity = torch.matmul(Q, torch.transpose(K, 1, 2))/torch.sqrt(d)\n",
    "        \n",
    "        # mask the diagonal value\n",
    "        mask = torch.eye(item_embedding.size(1), item_embedding.size(1)).byte().cuda()\n",
    "        affinity = affinity.masked_fill(mask, 0)\n",
    "        S = F.softmax(affinity)\n",
    "        A = torch.mean(torch.matmul(S, item_embedding), dim=1)\n",
    "        return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttSeqModel(nn.Module):\n",
    "    def __init__(self, num_user, num_item, L, w, embedding_dim):\n",
    "        \"\"\"\n",
    "        num_user: int, user number in dataset\n",
    "        num_item: int, item number in dataset\n",
    "        L: int the number of history item will consider\n",
    "        embeding_dim: int, laten vector dim of item\n",
    "        \"\"\"\n",
    "        super(AttSeqModel, self).__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.num_item = num_item\n",
    "        self.L = L\n",
    "        self.user_embed = nn.Embedding(num_user, embedding_dim)\n",
    "        self.item_embed_short = nn.Embedding(num_item, embedding_dim)\n",
    "        self.item_embed_long = nn.Embedding(num_item, embedding_dim)\n",
    "        self.item_position_embed = nn.Embedding.from_pretrained(self.position_embed(L),freeze=True)\n",
    "        self.att = SelfAttenion(embedding_dim).cuda()\n",
    "        self.w = w\n",
    "        \n",
    "        # embedding init\n",
    "        self.user_embed.weight.data.normal_(0,1.0/self.user_embed.embedding_dim)\n",
    "        self.item_embed_short.weight.data.normal_(0, 1.0/self.item_embed_short.embedding_dim)\n",
    "        self.item_embed_long.weight.data.normal_(0, 1.0/self.item_embed_long.embedding_dim)\n",
    "        \n",
    "    def position_embed(self, L):\n",
    "        position_embedding = np.array([[pos/np.power(1000, 2.*i)/ self.embedding_dim for i in range(self.embedding_dim)]\n",
    "                                      for pos in range(L)])\n",
    "        position_embedding[:,0::2] = np.sin(position_embedding[:,0::2])\n",
    "        position_embedding[:,1::2] = np.cos(position_embedding[:,1::2])\n",
    "        return torch.from_numpy(position_embedding).cuda()\n",
    "    \n",
    "    def forward(self, user, seq_item, target=None, for_pred=False):\n",
    "        \"\"\"\n",
    "        user: uid of user\n",
    "        seq_item: L item id user interacte before\n",
    "        target: item\n",
    "        \"\"\"\n",
    "        # sequential item embedding\n",
    "        item_embedding = self.item_embed_short(seq_item)  # L*d\n",
    "        # item position embedding\n",
    "        position_idx = torch.range(0,self.L-1).unsqueeze(0).expand(seq_item.size(0),-1).long().cuda()\n",
    "        position_embedding = self.item_position_embed(position_idx)\n",
    "        # add position embedding\n",
    "        item_embedding_cat = item_embedding.float() + position_embedding.float()\n",
    "        \n",
    "        # attention\n",
    "        attention = self.att(item_embedding_cat)\n",
    "        \n",
    "        # user embedding\n",
    "        user_embedding = self.user_embed(user).squeeze()\n",
    "        # target embedding short and long note: those two embedding is different \n",
    "        if target is None:\n",
    "            target = torch.range(0,self.num_item-1).long().unsqueeze(0).cuda()\n",
    "            target_embedding_short = self.item_embed_short(target).squeeze()\n",
    "            target_embedding_long = self.item_embed_long(target).squeeze()\n",
    "        else:\n",
    "            target_embedding_short = self.item_embed_short(target).squeeze()\n",
    "            target_embedding_long = self.item_embed_long(target).squeeze()\n",
    "        # pred\n",
    "        if for_pred == False:\n",
    "            user_embedding = user_embedding.unsqueeze(1).expand(-1,target.size(1),-1)\n",
    "            attention = attention.unsqueeze(1).expand(-1,target.size(1),-1)\n",
    "            y_pred = self.w* torch.sqrt(torch.sum((user_embedding - target_embedding_long)**2, dim=2)) + (1-self.w)*torch.sqrt(torch.sum((attention-target_embedding_short)**2, dim=2))\n",
    "            return y_pred\n",
    "        else:\n",
    "            user_embedding = user_embedding.unsqueeze(0).expand(target.size(1),-1)\n",
    "            attention = attention.expand(target.size(1),-1)\n",
    "            y_pred = self.w* torch.sqrt(torch.sum((user_embedding - target_embedding_long)**2, dim=1)) + (1-self.w)*torch.sqrt(torch.sum((attention-target_embedding_short)**2, dim=1))\n",
    "            return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "num_user = len(data['user'].unique())\n",
    "num_item = len(data['item'].unique())\n",
    "L = 5\n",
    "embedding_dim = 100\n",
    "w = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, test_data, epochs):\n",
    "    model.train()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001,weight_decay=0.0001)\n",
    "    for epoch in range(epochs):\n",
    "        losses = []\n",
    "        start = time.time()\n",
    "        for train_x, train_y in dataloader:\n",
    "            user = train_x[:,0].cuda()\n",
    "            item_seq = train_x[:,1:].cuda()\n",
    "            target_pos = train_y[:,:3].cuda()\n",
    "            target_neg = train_y[:,3:].cuda()\n",
    "            y_pred_pos = model(user, item_seq, target_pos,for_pred=False)\n",
    "            y_pred_neg = model(user, item_seq, target_neg, for_pred=False)\n",
    "            optimizer.zero_grad()\n",
    "            loss = torch.zeros(y_pred_pos.size(0),1).cuda()\n",
    "            for i in range(y_pred_pos.size(1)):\n",
    "                l = y_pred_pos[:,i].view(-1,1)\n",
    "                y_pos_slice = l.expand(-1,y_pred_pos.size(1))\n",
    "                loss += torch.sum(y_pos_slice - y_pred_neg + 0.5,dim=1).unsqueeze(1)\n",
    "            loss = torch.mean(loss)\n",
    "            losses.append(loss.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(\"Epoch %d loss is %.3f and consume time is %.2f\" %(epoch+1, np.mean(losses), (time.time() - start)))\n",
    "        hr, mrr = test(model, test_data, 50)\n",
    "        print(\"hr is %.3f and mrr is %.3f\" %(hr, mrr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hr(y_target, y_pred, topk):\n",
    "    y_pred = y_pred[:topk].cpu().numpy()\n",
    "    for item in y_pred:\n",
    "        if item in y_target:\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "def mrr(y_target, y_pred, topk):\n",
    "    y_pred = y_pred[:topk].cpu().numpy()\n",
    "    for idx in range(len(y_pred)):\n",
    "        if y_pred[idx] in y_target:\n",
    "            return 1/(idx+1)\n",
    "    return 0\n",
    "\n",
    "def test(model, test_data, topk):\n",
    "    model.eval()\n",
    "    HR = []\n",
    "    MRR = []\n",
    "    for idx in range(test_data.size(0)):\n",
    "        uid = test_data[idx,0].unsqueeze(0).cuda()\n",
    "        item_seq = test_data[idx, 1:6].unsqueeze(0).cuda()\n",
    "        y_target = test_data[idx,6:9].numpy()\n",
    "        y_pred = model(uid, item_seq,for_pred=True)\n",
    "        y_pred = torch.argsort(y_pred)\n",
    "        hits = hr(y_target, y_pred, topk)\n",
    "        mrrs = mrr(y_target, y_pred, topk)\n",
    "        HR.append(hits)\n",
    "        MRR.append(mrrs)\n",
    "    return np.mean(HR), np.mean(MRR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 loss is -12.691 and consume time is 20.85\n",
      "hr is 0.036 and mrr is 0.002\n",
      "Epoch 2 loss is -35.784 and consume time is 20.82\n",
      "hr is 0.052 and mrr is 0.005\n",
      "Epoch 3 loss is -49.472 and consume time is 20.62\n",
      "hr is 0.053 and mrr is 0.004\n",
      "Epoch 4 loss is -57.987 and consume time is 21.19\n",
      "hr is 0.067 and mrr is 0.004\n",
      "Epoch 5 loss is -63.308 and consume time is 21.00\n",
      "hr is 0.069 and mrr is 0.005\n",
      "Epoch 6 loss is -66.359 and consume time is 21.51\n",
      "hr is 0.066 and mrr is 0.004\n",
      "Epoch 7 loss is -68.033 and consume time is 21.37\n",
      "hr is 0.070 and mrr is 0.004\n",
      "Epoch 8 loss is -68.973 and consume time is 21.21\n",
      "hr is 0.065 and mrr is 0.004\n",
      "Epoch 9 loss is -69.495 and consume time is 20.56\n",
      "hr is 0.064 and mrr is 0.005\n",
      "Epoch 10 loss is -69.803 and consume time is 21.15\n",
      "hr is 0.070 and mrr is 0.006\n",
      "Epoch 11 loss is -70.007 and consume time is 21.57\n",
      "hr is 0.061 and mrr is 0.005\n",
      "Epoch 12 loss is -70.078 and consume time is 21.66\n",
      "hr is 0.061 and mrr is 0.005\n",
      "Epoch 13 loss is -70.162 and consume time is 21.33\n",
      "hr is 0.072 and mrr is 0.005\n",
      "Epoch 14 loss is -70.186 and consume time is 21.13\n",
      "hr is 0.061 and mrr is 0.004\n",
      "Epoch 15 loss is -70.215 and consume time is 21.03\n",
      "hr is 0.071 and mrr is 0.005\n",
      "Epoch 16 loss is -70.217 and consume time is 21.02\n",
      "hr is 0.068 and mrr is 0.005\n",
      "Epoch 17 loss is -70.243 and consume time is 20.91\n",
      "hr is 0.068 and mrr is 0.005\n",
      "Epoch 18 loss is -70.222 and consume time is 20.95\n",
      "hr is 0.067 and mrr is 0.005\n",
      "Epoch 19 loss is -70.237 and consume time is 21.03\n",
      "hr is 0.064 and mrr is 0.005\n",
      "Epoch 20 loss is -70.252 and consume time is 21.30\n",
      "hr is 0.068 and mrr is 0.005\n"
     ]
    }
   ],
   "source": [
    "selfatt = AttSeqModel(num_user, num_item, L, w, embedding_dim).cuda()\n",
    "train(selfatt,dataloader,test_data,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

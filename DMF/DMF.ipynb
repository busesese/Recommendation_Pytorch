{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wenyi/软件/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "      <th>timeStamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978300760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "      <td>978302109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "      <td>978301968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "      <td>978300275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "      <td>978824291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user  item  rating  timeStamp\n",
       "0     1  1193       5  978300760\n",
       "1     1   661       3  978302109\n",
       "2     1   914       3  978301968\n",
       "3     1  3408       4  978300275\n",
       "4     1  2355       5  978824291"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../data/ml-1m/ratings.dat', sep='::', names=['user','item', 'rating', 'timeStamp'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "user2id = {}\n",
    "for idx, uid in enumerate(data['user'].unique().tolist()):\n",
    "    user2id[uid] = idx\n",
    "data['user'] = data['user'].map(user2id)\n",
    "\n",
    "item2id = {}\n",
    "for idx, itemid in enumerate(data['item'].unique().tolist()):\n",
    "    item2id[itemid] = idx\n",
    "data['item'] = data['item'].map(item2id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user  item  rating\n",
       "0     0     0       5\n",
       "1     0     1       3\n",
       "2     0     2       3\n",
       "3     0     3       4\n",
       "4     0     4       5"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[['user', 'item', 'rating']]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u\n",
      "i\n",
      "r\n"
     ]
    }
   ],
   "source": [
    "for row in data:\n",
    "    print(row[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DMF(nn.Module):\n",
    "    def __init__(self,data, hidden1, hidden2, outputs):\n",
    "        \"\"\"\n",
    "        data: dataFrame of [user, item, rating]\n",
    "        \"\"\"\n",
    "        super(DMF, self).__init__()\n",
    "        self.data = data\n",
    "        self.num_user = len(data['user'].unique())\n",
    "        self.num_item = len(data['item'].unique())\n",
    "        print(self.num_user, self.num_item)\n",
    "        self.hidden1 = hidden1\n",
    "        # 构建初始的embedding向量，这里user embedding是利用user对历史item的打分vector\n",
    "        # item embedding 是利用item历史被若干user打分的vector\n",
    "        self.user_item_matrix = self.generate_useritem_matrix(data)\n",
    "        weight_user_item = torch.FloatTensor(self.user_item_matrix)\n",
    "        weight_item_user = torch.FloatTensor(self.user_item_matrix.T)\n",
    "        self.user_embed = nn.Embedding.from_pretrained(weight_user_item, freeze=True)\n",
    "        self.item_embed = nn.Embedding.from_pretrained(weight_item_user, freeze=True)\n",
    "        \n",
    "        self.fc_user = nn.Linear(self.num_item, hidden1)\n",
    "        self.fc_item = nn.Linear(self.num_user, hidden1)\n",
    "        # MLP网络\n",
    "        self.mlp_model = nn.Sequential(\n",
    "                        nn.Linear(hidden1, hidden2),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Linear(hidden2, outputs)\n",
    "                    )\n",
    "        \n",
    "    def generate_useritem_matrix(self, data):\n",
    "        user_item_matrix = np.zeros([self.num_user, self.num_item], np.float32)\n",
    "        for row in data.values:\n",
    "            user = row[0]\n",
    "            item = row[1]\n",
    "            rating = row[2]\n",
    "            user_item_matrix[user][item] = rating\n",
    "        return user_item_matrix\n",
    "            \n",
    "    def forward(self, user, item):\n",
    "        user_input = self.user_embed(user)\n",
    "        item_input = self.item_embed(item)\n",
    "        hidden1_user = F.relu(self.fc_user(user_input))\n",
    "        hidden1_item = F.relu(self.fc_item(item_input))\n",
    "        user_output = self.mlp_model(hidden1_user)\n",
    "        item_output = self.mlp_model(hidden1_item)\n",
    "        norm_user_output = torch.sqrt(torch.sum(user_output**2, dim=1))\n",
    "        norm_item_output = torch.sqrt(torch.sum(item_output**2, dim=1))\n",
    "        predict = torch.sum(user_output*item_output,dim=1)/(norm_user_output*norm_item_output)\n",
    "        predict = torch.clamp(predict,1e-6)\n",
    "        return predict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Dataloader:\n",
    "    def __init__(self, data):\n",
    "        \"\"\"\n",
    "        data: DataFrame ['user', 'item', 'rating']\n",
    "        \"\"\"\n",
    "        self.num_user = len(data['user'].unique())\n",
    "        self.num_item = len(data['item'].unique())\n",
    "\n",
    "        self.train, self.test = self.getTrainTest(data)\n",
    "        self.trainDict = self.getTrainDict(self.train)\n",
    "        \n",
    "    def getTrainTest(self, data):\n",
    "        data = data.sort_values(by=['user','rating'])\n",
    "        train = pd.DataFrame()\n",
    "        test = []\n",
    "        for user in data['user'].unique():\n",
    "            df = data[data['user']==user]\n",
    "            df_train = df.iloc[:-1,:]\n",
    "            df_test = df.iloc[-1,:].values\n",
    "            if train.empty:\n",
    "                train = df_train\n",
    "            else:\n",
    "                train = pd.concat((train, df_train))\n",
    "            test.append(df_test)\n",
    "        return train, pd.DataFrame(test)\n",
    "    \n",
    "    def getTrainDict(self,data):\n",
    "        trainDict = {}\n",
    "        for row in data.values:\n",
    "            user = row[0]\n",
    "            item = row[1]\n",
    "            rating = row[2]\n",
    "            trainDict[(user, item)] = rating\n",
    "        return trainDict\n",
    "    \n",
    "    def generate_train_dataset(self, negative_num):\n",
    "        user_item = []\n",
    "        rating = []\n",
    "        for user_items, r in self.trainDict.items():\n",
    "            user_item.append(list(user_items))\n",
    "            rating.append(r)\n",
    "            for t in range(negative_num):\n",
    "                j = np.random.randint(self.num_item)\n",
    "                while (user_items[0], j) in self.trainDict:\n",
    "                    j = np.random.randint(self.num_item)\n",
    "                user_item.append([user_items[0], j])\n",
    "                rating.append(0.0)\n",
    "        return np.array(user_item), np.array(rating)\n",
    "    \n",
    "    def generate_test_dataset(self, negative_num_test=99):\n",
    "        user_item = []\n",
    "        for row in self.test.values:\n",
    "            tmp_user_item = []\n",
    "            u = row[0]\n",
    "            i = row[1]\n",
    "            tmp_user_item.append([u, i])\n",
    "            neglist = set()\n",
    "            neglist.add(i)\n",
    "            for t in range(negative_num):\n",
    "                j = np.random.randint(self.num_item)\n",
    "                while (row[0], j) in self.trainDict or j in neglist:\n",
    "                    j = np.random.randint(self.num_item)\n",
    "                neglist.add(j)\n",
    "                tmp_user_item.append([row[0],j])\n",
    "            user_item.append(tmp_user_item)\n",
    "        return np.array(user_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas = Dataloader(data)\n",
    "x_train, y_train = datas.generate_train_dataset(5)\n",
    "x_test = datas.generate_test_dataset(99)\n",
    "\n",
    "x_train = torch.from_numpy(x_train)\n",
    "y_train = torch.from_numpy(y_train)\n",
    "train_dataset = TensorDataset(x_train, y_train)\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6040 3706\n"
     ]
    }
   ],
   "source": [
    "dmf = DMF(data, 128, 64, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(model, epochs, maxRate,batch_size=256, lr=0.01):\n",
    "    optimizer = optim.Adam(model.parameters(),lr=lr)\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        losses = []\n",
    "        print(\"Training epoch %d\" %(epoch+1))\n",
    "        for i, data in enumerate(train_loader):\n",
    "            data_x = data[0]\n",
    "            data_y = data[1]\n",
    "            y_pred = model(data_x[:,0], data_x[:,1])\n",
    "            regRate = data_y/maxRate\n",
    "            loss =regRate * torch.log(y_pred.double()) + (1-regRate)*torch.log(1-y_pred.double())\n",
    "            loss = -torch.mean(loss)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            losses.append(loss.item())\n",
    "        print(\"loss is %.3f\"%(sum(losses)/len(losses)))\n",
    "        hr, ndcg = test(x_test, model)\n",
    "        print(\"EVAL hr %.3f ndcg %.3f\" %(hr, ndcg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  计算逻辑：target为测试集的目标item， ranklist是对每个用户的1个真实目标item和进行负采样的99个item的预测评分的排序\n",
    "# 然后取topk个，如果target在这预测的topk的ranklist中表示命中，记录命中的位置（因为NDCG是衡量排序结果好坏的指标与命中位置有关）\n",
    "def getNDCG(ranklist, target):\n",
    "    for i in range(len(ranklist)):\n",
    "        item = ranklist[i]\n",
    "        if item == target:\n",
    "            return math.log(2)/math.log(i+2)\n",
    "    return 0\n",
    "\n",
    "#  计算逻辑：target为测试集的目标item， ranklist是对每个用户的1个真实目标item和进行负采样的99个item的预测评分的排序\n",
    "# 然后取topk个，如果target在这预测的topk的ranklist中表示命中，return 1 反之 return0\n",
    "def getHR(ranklist, target):\n",
    "    for item in ranklist:\n",
    "        if item == target:\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "def test(x_test, model,topk=10):\n",
    "    model.eval()\n",
    "    hr = []\n",
    "    NDCG = []\n",
    "    x_test = torch.from_numpy(x_test)\n",
    "    test_user = x_test[:,:,0]\n",
    "    test_item = x_test[:,:,1]\n",
    "    for i in range(test_user.shape[0]):\n",
    "        target = test_item[i][0]\n",
    "        predict = model(test_user[i], test_item[i])\n",
    "        ranklist = sorted(zip(test_item[i], predict), key=lambda x:x[1])[:topk]\n",
    "        ranklist = [item.item() for item, val in ranklist]\n",
    "        tmp_hr = getHR(ranklist, target)\n",
    "        hr.append(tmp_hr)\n",
    "        tmp_ndcg = getNDCG(ranklist, target)\n",
    "        NDCG.append(tmp_ndcg)\n",
    "    return np.mean(hr), np.mean(NDCG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-252-059c57aafa69>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdmf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-250-26815b8a4b88>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, epochs, maxRate, batch_size, lr)\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loss is %.3f\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/软件/anaconda3/lib/python3.6/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "%%time\n",
    "train(dmf, 3, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 经过上述计算可以得到user和item的low dimension表示，这个表示可以用来计算用户对item的评分,用余弦相似度计算，然后取TopK进行推荐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_embeding = dmf."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
